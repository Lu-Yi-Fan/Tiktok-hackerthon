{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel('ads_dim3.xlsx')\n",
    "columns_to_regress= ['ad_id', 'log_punish', 'log_ad_revenue', 'log_avg_ad_revenue', 'log_baseline_st', 'days_since_punish', 'ad_run_time']\n",
    "df = df[columns_to_regress]\n",
    "df.to_excel('TrainingData.xlsx', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using\n",
    "# - log_ad_rev\n",
    "# - log_avg_ad_rev\n",
    "# - log_baseline_st\n",
    "# - log_punish\n",
    "# - ad_run_time\n",
    "\n",
    "trainingData = pd.read_excel('TrainingData.xlsx')\n",
    "df_lr = trainingData.copy()\n",
    "df_gb = trainingData.copy()\n",
    "\n",
    "inf_count_lr = np.isinf(df_lr).sum()\n",
    "inf_count_gb = np.isinf(df_gb).sum()\n",
    "\n",
    "# Replace infinities with NaN\n",
    "df_lr = df_lr.replace([np.inf, -np.inf], np.nan)\n",
    "df_gb = df_gb.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df_lr = df_lr.dropna()\n",
    "df_gb = df_gb.dropna()\n",
    "\n",
    "ad_id_lr = df_lr['ad_id']\n",
    "df_lr.drop(['ad_id'], axis=1, inplace=True)\n",
    "\n",
    "ad_id_gb = df_gb['ad_id']\n",
    "df_gb.drop(['ad_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use linear regression\n",
    "coefs = {var: [] for var in df_lr.columns}\n",
    "intercepts = []\n",
    "\n",
    "for column in df_lr.columns:\n",
    "    X = df_lr.drop(column, axis=1)\n",
    "    y = df_lr[column]\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    print(f\"Dependent variable: {column}\")\n",
    "    print(\"Coefficients:\")\n",
    "    for var, coef in zip(X.columns, reg.coef_):\n",
    "        print(f\"{var}: {coef}\")\n",
    "        coefs[var].append(coef)\n",
    "    print(f\"Intercept: {reg.intercept_}\")\n",
    "    intercepts.append(reg.intercept_)\n",
    "    print('\\n')\n",
    "\n",
    "# Calculate the average coefficient for each independent variable\n",
    "avg_coefs = {var: sum(coefs[var])/len(coefs[var]) for var in coefs}\n",
    "# Calculate the average intercept\n",
    "avg_intercept = sum(intercepts)/len(intercepts)\n",
    "print(\"Average coefficients:\")\n",
    "for var, avg_coef in avg_coefs.items():\n",
    "    print(f\"{var}: {avg_coef}\")\n",
    "print(f\"Average intercept: {avg_intercept}\")\n",
    "\n",
    "# linear regression Average coefficients:\n",
    "# log_punish: 7.18014209372482\n",
    "# log_ad_revenue: -0.06443096647832146\n",
    "# log_avg_ad_revenue: 1.5943043804097148\n",
    "# log_baseline_st: -4.4893339410854285\n",
    "# days_since_punish: 0.017953594309575514\n",
    "# ad_run_time: 0.015548906340517537\n",
    "# Average intercept: 30.71252983647334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average coefficients and intercept for linear regression\n",
    "avg_coefs = {\n",
    "    'log_punish': 7.18014209372482,\n",
    "    'log_ad_revenue': -0.06443096647832146,\n",
    "    'log_avg_ad_revenue': 1.5943043804097148,\n",
    "    'log_baseline_st': -4.4893339410854285,\n",
    "    'days_since_punish': 0.017953594309575514,\n",
    "    'ad_run_time': 0.015548906340517537\n",
    "}\n",
    "avg_intercept = 30.71252983647334\n",
    "\n",
    "# Define the independent variables\n",
    "X = df_lr[list(avg_coefs.keys())]\n",
    "\n",
    "# Calculate the weighted average of the independent variables\n",
    "y_pred = X.dot(np.array(list(avg_coefs.values()))) + avg_intercept\n",
    "\n",
    "# Add the ad_id column and the predicted values for Y back to the DataFrame\n",
    "df_lr['ad_id'] = ad_id_lr\n",
    "df_lr['y_pred'] = y_pred\n",
    "df_lr.to_excel('df_lr.xlsx',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gradient boosting regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# Initialize a dictionary to store the feature importances for each independent variable\n",
    "importances = {var: [] for var in df_gb.columns}\n",
    "# Initialize a list to store the intercepts for each dependent variable\n",
    "intercepts = []\n",
    "\n",
    "for column in df_gb.columns:\n",
    "    X = df_gb.drop(column, axis=1)\n",
    "    y = df_gb[column]\n",
    "    reg = GradientBoostingRegressor().fit(X, y)\n",
    "    print(f\"Dependent variable: {column}\")\n",
    "    print(\"Feature importances:\")\n",
    "    for var, imp in zip(X.columns, reg.feature_importances_):\n",
    "        print(f\"{var}: {imp}\")\n",
    "        importances[var].append(imp)\n",
    "    intercepts.append(reg.init_.constant_[0][0])\n",
    "    print('\\n')\n",
    "\n",
    "# Calculate the average feature importance for each independent variable\n",
    "avg_importances = {var: sum(importances[var])/len(importances[var]) for var in importances}\n",
    "# Calculate the average intercept\n",
    "avg_intercept = sum(intercepts)/len(intercepts)\n",
    "\n",
    "print(\"Average feature importances:\")\n",
    "for var, avg_imp in avg_importances.items():\n",
    "    print(f\"{var}: {avg_imp}\")\n",
    "print(f\"Average intercept: {avg_intercept}\")\n",
    "\n",
    "# GradientBoostingRegressor Average feature importances:\n",
    "# log_punish: 0.06812327966619008\n",
    "# log_ad_revenue: 0.21249643834898407\n",
    "# log_avg_ad_revenue: 0.3230820880240495\n",
    "# log_baseline_st: 0.15432104027909502\n",
    "# days_since_punish: 0.10371900675908725\n",
    "# ad_run_time: 0.33825814692259415\n",
    "# Average intercept: 4.2656448978951085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting average feature importances and intercept\n",
    "\n",
    "avg_importances = {\n",
    "    'log_punish': 0.06812327966619008,\n",
    "    'log_ad_revenue': 0.21249643834898407,\n",
    "    'log_avg_ad_revenue': 0.3230820880240495,\n",
    "    'log_baseline_st': 0.15432104027909502,\n",
    "    'days_since_punish': 0.10371900675908725,\n",
    "    'ad_run_time': 0.33825814692259415\n",
    "}\n",
    "avg_intercept = 4.2656448978951085\n",
    "# Define the independent variables\n",
    "X = df_gb[list(avg_importances.keys())]\n",
    "# Calculate the weighted average of the independent variables\n",
    "y_pred = X.dot(np.array(list(avg_importances.values()))) + avg_intercept\n",
    "\n",
    "df_gb['ad_id'] = ad_id_gb\n",
    "df_gb['y_pred'] = y_pred\n",
    "df_gb.to_excel('df_gb.xlsx',index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
